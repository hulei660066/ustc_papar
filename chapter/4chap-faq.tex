
\chapter{用户兴趣探索}
\label{chap:interestExplore}
电子商务产品的设计往往是数据驱动的，即许多产品方面的决策都是把用户行为量化后得出的。但就商品而言，那些热门主题往往只代表了用户一小部分的个性化需求，只有通过对用户行为的充分分析，才能更好的挖掘出用户的兴趣，最终提升商品的销售量。现有的推荐算法注重用户或资源间的相似性的同时却忽略了用户兴趣的动态变化，从而导致系统在时间维度上有偏离用户需求的趋势。

为了更好的探索用户兴趣，手机主题推荐系统充分利用了用户画像和商品特征表。用户画像包括基本信息和兴趣特征向量,商品特征向量表包括分类、标签、适用人群等，给定某用户行为，用户兴趣探索过程分为如下几个步骤：首先，利用用户历史行为(评论,停留时长,评分,点赞,购买等)建模量化用户满意度,然后，利用用户兴趣特征向量与商品特征向量得出相关分数，如果商品与用户的相关分数很低,但有很高的用户满意度,说明是一次成功的用户兴趣探索,更新用户画像。如果是热门商品,大量的用户都会点击,但商品与用户不是很相关,则认为其探索效果是有限的,反之如果是小众商品,考虑到长尾效应,则可以认为其是更成功的兴趣探索。这里涉及到的关键概念包括用户满意度的量化、小众标签的定向挖掘、用户兴趣的动态化。

本章内容首先介绍海量用户行为数据的存储方式。用户行为数据拥有区别于传统数据库数据的特点有，用户行为数据量巨大，常面临TB甚至PB级的数据；含有较多的噪音；多维聚合式查询。针对这些特征，用户行为数据采用Hbase数据集群存储和hadoop集群计算。然后，介绍用户兴趣探索的算法模型；然后，介绍如何通过用户行为的分析量化用户满意度。最后，介绍小众兴趣标签的挖掘。

\section{用户行为数据的存储}
手机主题用户行为数据的特点包括：用户基数庞大。手机主题注册用户达千万级，活跃用户达百万级；用户规模增长快。月新注册用户达10万数量级。每个用户的行为数量较小。即使是活跃用户，每天最多也只能产生上百条行为记录，每年不超过十万条；用户行为的计算较为复杂。计算用户的两次登录间隔天数、反复购买的商品、累积在线时间，这些都是针对用户行为的计算，通常具有一定的复杂性；用户行为数据格式不规整，字段丢失率较高。根据用户行为数据的这些特点，我们采用基于Hadop分布式的架构。Hadop又如下几个优点：
\begin{itemize}
\item 高可靠性。Hadoop按位存储和处理数据的能力使其具有高可靠性。
\item 高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以根据用户增长规模方便地扩展到数以千计的节点中。
\item 高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。
\item 高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。
\item 低成本。hadoop是开源的，项目的软件成本因此会大大降低。
\end{itemize}
Hadoop的框架最核心的设计是HDFS和MapReduce。HDFS为海量的数据提供了存储，则MapReduce为海量的数据提供了计算。接下来首先介绍HDFS的体系架构，然后介绍MapReduce。
  \subsection{HDFS的体系架构}
  HDFS采用主从(Master/Slave)结构模型，一个HDFS集群是由一个NameNode和若干个DataNode组成的(在最新的Hadoop2.2版本已经实现多个NameNode的配置)。NameNode作为主服务器，管理文件系统命名空间和客户端对文件的访问操作。DataNode管理存储的数据。HDFS支持文件形式的数据。从内部来看，文件被分成若干个数据块，这若干个数据块存放在一组DataNode上。NameNode执行文件系统的命名空间，如打开、关闭、重命名文件或目录等，也负责数据块到具体DataNode的映射。DataNode负责处理文件系统客户端的文件读写，并在NameNode的统一调度下进行数据库的创建、删除和复制工作。NameNode是所有HDFS元数据的管理者，用户数据永远不会经过NameNode，HDFS体系结构图如\autoref{pic:hl_hadoop}所示。
  \begin{figure}
  \centering
    \framebox{\includegraphics[scale=0.4]{figures/hl_hadoop}}
    \figcaption{HDFS体系结构}
    \label{pic:hl_hadoop}
  \end{figure}

  其中，NameNode、DataNode、Client。NameNode是管理者，DataNode是文件存储者、Client是需要获取分布式文件系统的应用程序。HDFS作为分布式文件系统在数据管理方面设计了多重容错冗余：一个Block会有三份备份，一份在NameNode指定的DateNode上，一份放在与指定的DataNode不在同一台机器的DataNode上，一根在于指定的DataNode在同一Rack上的DataNode上。备份的目的是为了数据安全，采用这种方式是为了考虑到同一Rank失败的情况，以及不同数据拷贝带来的性能的问题。
  \begin{itemize}
  \item 文件写入：首先，Client向NameNode发起文件写入的请求；然后，NameNode根据文件大小和文件块配置情况，返回给Client它管理的DataNode的信息；最后，Client将文件划分为多个block，根据DataNode的地址，按顺序将block写入DataNode块中。
  \item 文件读取：首先，Client向NameNode发起读取文件的请求；然后，NameNode返回文件存储的DataNode信息；最后，Client读取文件信息。
  \end{itemize}

  \subsection{MapReduce体系架构}
  MR框架是由一个单独运行在主节点上的JobTracker和运行在每个集群从节点上的TaskTracker共同组成。主节点负责调度构成一个作业的所有任务，这些任务分布在不同的不同的从节点上。主节点监视它们的执行情况，并重新执行之前失败的任务。从节点仅负责由主节点指派的任务。当一个Job被提交时，JobTracker接受到提交作业和配置信息之后，就会将配置信息等分发给从节点，同时调度任务并监控TaskTracker的执行。JobTracker可以运行于集群中的任意一台计算机上。TaskTracker负责执行任务，它必须运行在DataNode上，DataNode既是数据存储节点，也是计算节点。JobTracker将map任务和reduce任务分发给空闲的TaskTracker，这些任务并行运行，并监控任务运行的情况。如果JobTracker出了故障，JobTracker会把任务转交给另一个空闲的TaskTracker重新运行。

  HDFS和MR共同组成Hadoop分布式系统体系结构的核心。HDFS在集群上实现了分布式文件系统，MR在集群上实现了分布式计算和任务处理。HDFS在MR任务处理过程中提供了文件操作和存储等支持，MR在HDFS的基础上实现了任务的分发、跟踪、执行等工作，并收集结果，二者相互作用，完成分布式集群的主要任务。Hadoop上的并行应用程序开发是基于MR编程框架。MR编程模型原理：利用一个输入的key-value对集合来产生一个输出的key-value对集合。MR库通过Map和Reduce两个函数来实现这个框架。用户自定义的map函数接受一个输入的key-value对，然后产生一个中间的key-value对的集合。MR把所有具有相同的key值的value结合在一起，然后传递个reduce函数。Reduce函数接受key和相关的value结合，reduce函数合并这些value值，形成一个较小的value集合。通常我们通过一个迭代器把中间的value值提供给reduce函数，这样就可以处理无法全部放在内存中的大量的value值集合了。

  MapReduce体系中数据流动过程：首先，大数据集被分成众多小的数据集块，若干个数据集被分在集群中的一个节点进行处理并产生中间结果。然后，单节点上的任务，map函数一行行读取数据获得数据的(k1,v1)，数据进入缓存，通过map函数执行map(基于key-value)排序执行后输入(k2,v2)，有时候在map之后reduce之前有一个数据合并(Combine)操作，即将中间有相同的key的对合并，Combine能减少中间结果key-value对的数目，从而降低网络流量。最后，不同机器上的(k2,v2)通过merge排序的过程，reduce合并得到，(k3,v3)，输出到HDFS文件中。数据流示意图如\autoref{pic:hl_MapReduce}所示。值得一提的是，Map任务的中间结果在做完Combine和Partition后，以文件的形式存于本地磁盘上。中间结果文件的位置会通知主控JobTracker，JobTracker再通知reduce任务到哪一个DataNode上去取中间结果。所有的map任务产生的中间结果均按其key值按hash函数划分成R份，R个reduce任务各自负责一段key区间。每个reduce需要向许多个map任务节点取的落在其负责的key区间内的中间结果，然后执行reduce函数，最后形成一个最终结果。有R个reduce任务，就会有R个最终结果，很多情况下这R个最终结果并不需要合并成一个最终结果，因为这R个最终结果可以作为另一个计算任务的输入，开始另一个并行计算任务。这就形成了多个输出数据片段(HDFS副本)。
  \begin{figure}
  \centering
    \framebox{\includegraphics[scale=0.5]{figures/hl_MapReduce}}
    \figcaption{MapReduce数据流}
    \label{pic:hl_MapReduce}
  \end{figure}

  \subsection{Hbase数据管理}
  Hbase作为Hadoop数据仓库。与传统的mysql、oracle还是有很大的差别。NoSql数据库与传统关系型数据的区别有如下几个方面：
  \begin{itemize}
  \item Hbase适合大量插入同时又有读的情况。输入一个Key获取一个value或输入一些key获得一些value。
  \item Hbase的瓶颈是硬盘传输速度。Hbase的操作包括往数据里面insert数据，update的实际上也是insert，只是插入一个新的时间戳的一行。Delete数据也是insert，只是insert一行带有delete标记的一行。Hbase的所有操作都是追加插入操作。Hbase是一种日志集数据库。存储方式像是日志文件一样，是批量大量的往硬盘中写，通常都是以文件形式的读写。所以读写速度就取决于硬盘与机器之间的传输有多快。而Oracle的瓶颈是硬盘寻道时间。其经常的操作时随机读写。要update一个数据，先要在硬盘中找到这个block，然后将其读入内存，在内存中的缓存中修改，过段时间再回写回去。硬盘的寻道时间主要由转速来决定的，所以形成了寻道时间瓶颈。
  \item Hbase中数据可以保存许多不同时间戳的版本。数据按时间排序，因此Hbase特别适合寻找按照时间排序寻找Top n的场景。找出某个人最近浏览的主题，最近购买的N款主题包，N种行为等等，因此Hbase在互联网应用非常多。
  \item Hbase的局限。只能做很简单的Key-value查询。它适合有高速插入，同时又有大量读的操作场景。而这种场景又很极端，并不是每一个公司都有这种需求。在一些公司，就是普通的OLTP(联机事务处理)随机读写。在这种情况下，Oracle的可靠性，系统的负责程度又比Hbase低一些。而且Hbase局限还在于它只有主键索引，因此在建模的时候就遇到了问题。
  \item Oracle是行式数据库，而Hbase是列式数据库。列式数据库的优势在于数据分析这种场景。数据分析与传统的OLTP的区别。数据分析，经常是以某个列作为查询条件，返回的结果也经常是某一些列，不是全部的列。在这种情况下，行式数据库反应的性能就很低效。
  \end{itemize}

  \subsection{Hive数据管理}
  Hive是建立在Hadoop上的数据仓库基础架构。它提供了一系列的工具，用来进行数据提取、转换、加载，是一种可以存储、查询和分析存储在Hadoop中的大规模数据机制。可以把Hadoop下结构化数据文件映射为一张成Hive中的表，并提供类sql查询功能，除了不支持更新、索引和事务，sql其它功能都支持。可以将sql语句转换为MapReduce任务进行运行，作为sql到MapReduce的映射器。提供shell、JDBC/ODBC、Thrift等接口。优点是成本低可以通过类sql语句快速实现简单的MapReduce统计。作为一个数据仓库，Hive的数据管理按照使用层次可以从元数据存储、数据存储和数据交换三个方面介绍。
  \begin{itemize}
  \item 元数据存储。Hive将元数据存储在RDBMS中，有三种方式可以连接到数据库：1）内嵌模式：元数据保持在内嵌数据库的Derby，一般用于单元测试，只允许一个会话连接；2）多用户模式：在本地安装Mysql，把元数据放到Mysql内；3）远程模式：元数据放置在远程的Mysql数据库。
  \item 数据存储。首先，Hive没有专门的数据存储格式，也没有为数据建立索引，用于可以非常自由的组织Hive中的表，只需要在创建表的时候告诉Hive数据中的列分隔符和行分隔符，这就可以解析数据了。其次，Hive中所有的数据都存储在HDFS中，Hive中包含4中数据模型：Tabel、ExternalTable、Partition、Bucket。Table类似与传统数据库中的Table，每一个Table在Hive中都有一个相应的目录来存储数据。例如：一个表zz，它在HDFS中的路径为：/wh/zz，其中wh是在hive-site.xml中由用户设定的数据仓库的目录，所有的Table数据(不含External Table)都保存在这个目录中。Partition类似于传统数据库中划分列的索引。在Hive中，表中的一个Partition对应于表下的一个目录，所有的Partition数据都存储在对应的目录中。例如：zz表中包含ds和city两个Partition，则对应于ds=20140214，city=beijing的HDFS子目录为：/wh/zz/ds=20140214/city=Beijing;Buckets对指定列计算的hash，根据hash值切分数据，目的是为了便于并行，每一个Buckets对应一个文件。将user列分数至32个Bucket上，首先对user列的值计算hash，比如，对应hash=0的HDFS目录为：/wh/zz/ds=20140214/city=Beijing/part-00000;对应hash=20的，目录为：/wh/zz/ds=20140214/city=Beijing/part-00020。ExternalTable指向已存在HDFS中的数据，可创建Partition。和Table在元数据组织结构相同，在实际存储上有较大差异。Table创建和数据加载过程，可以用统一语句实现，实际数据被转移到数据仓库目录中，之后对数据的访问将会直接在数据仓库的目录中完成。删除表时，表中的数据和元数据都会删除。ExternalTable只有一个过程，因为加载数据和创建表是同时完成。世界数据是存储在Location后面指定的HDFS路径中的，并不会移动到数据仓库中。
  \item 数据交换。用户接口包括客户端、Web界面和数据库接口，元数据通常存储在关系数据库如Mysql，Derby中。
  \end{itemize}
本小节主要介绍了Hadoop分布式计算平台最核心的分布式文件系统HDFS、MapReduce处理过程，以及数据仓库工具Hive和分布式数据库Hbase，基本涵盖了Hadoop分布式平台的所有技术核心。从体系架构到数据定义到数据存储再到数据处理，Hadoop分布式存储、计算平台为海量用户行为的分析和用户兴趣探索提供了可能。接下来的章节先介绍用户行为数据的分析，包括数据预处理和异常数据监测，然后介绍用户兴趣探索模块，包括算法模型、用户满意度量化、小众兴趣标签的挖掘。

\section{用户行为数据的的预处理}
数据预处理是数据挖掘过程中一个重要步骤，当原始数据存在不一致、重复、含噪声、维度高等问题时，更需要进行数据的预处理，以提高数据挖掘对象的质量，最终达到提高数据挖掘所获模式知识质量的目的。
  \subsection{背景}
  随着手机主题市场交易规模的逐步增大，积累下来的业务数据和用户行为数据越来越多，这些用户数据往往是电子商务平台最宝贵的财富。目前在手机主题推荐系统中大量地应用到了机器学习和数据挖掘技术，例如个性化推荐、搜索排序、用户画像建模等等，为企业创造了巨大的价值。本节主要介绍在用户兴趣探索实践中的数据预处理与特征挖掘方法。数据预处理主要工作是：
  \begin{itemize}
  \item 从原始数据，如文本、图像或者应用数据中清洗出特征数据和标注数据
  \item 对清洗出的特征和标注数据进行处理，例如样本采样，样本调权，异常点去除，特征归一化处理等过程。最终生成的数据主要是供模型直接使用。
  \end{itemize}

  \subsection{特征提取}
  用户兴趣探索的任务包括：探索用户的兴趣广度、兴趣深度、兴趣变动趋势。依据这些信息，推荐系统就能知道在面对某一个用户时要推荐哪几类型商品，每类商品所占的比例，未来几天推荐内容会有哪些变化。在确定了目标之后，接下来需要确定使用哪些数据来达到目标。提取哪些特征数据可能与用户是否点击购买相关，一方面可以借鉴一些业务经验，另一方面可以采用一些特征选择、特征分析等方法。从业务经验来判断，可能影响用户是否点击下单的因素有：
  \begin{itemize}
  \item 用户历史行为。对于老用户，之前可能有过点击、购买等行为。
  \item 用户实时兴趣。
  \item 用户满意度。上面的特征都是比较好衡量的，用户满意度可能是更复杂的一个特征，具体体现在用户评分、评价、购买后使用频率、时长等。
  \item 是否热门，商品评价人数，购买数等。
  \end{itemize}
  在确定好要使用哪些数据之后，还需要对使用数据的可用性进行评估，包括数据的获取难度，数据的规模，数据的准确率，数据的覆盖率等。
  \begin{itemize}
  \item 用户历史行为。只有老用户才会有行为，新用户是没有的。
  \item 数据获取难度。获取用户id不难，但是获取用户年龄和性别较困难，因为用户注册或者购买时，这些并不是必填项，即使填了也不完全准确。如果一些特征需要通过其他预测模型交叉验证的话，就存在着模型精度的问题。
  \item 数据覆盖率。数据覆盖率也是一个重要的考量因素，例如地理位置特征，并不是所有用户的距离我们都能获取到，PC端的就没有地理位置，还有很多用户禁止使用它们的定位功能。
  \item 用户实时行为。如果用户刚打开app，还没有任何行为，同样面临着一个冷启动的问题。
  \item 数据的准确率。有时候用户购买一款主题，不一定是其真心喜欢，可能是因为遇到限时半价、购买返现等活动。
  \end{itemize}

  \subsection{特征获取方式}
  特征提取方式分为在线提取和离线提取。

  离线特征获取方案。离线可以使用海量的数据，借助于分布式文件存储平台，例如HDFS等，使用例如MapReduce，Spark等处理工具来处理海量的数据等。

  在线特征获取方案。在线特征比较注重获取数据的延时，由于是在线服务，需要在非常短的时间内获取到相应的数据，对查找性能要求非常高，可以将数据存储在索引、key-value存储等，也可以使用Kafka等处理工具。Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：1）以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能；2）高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输；3）同时支持离线数据处理和实时数据处理；4）分布式系统，易于向外扩展。所有的producer、broker和consumer都会有多个，均为分布式的。无需停机即可扩展机器。

  \subsection{用户行为数据预处理}
  根据不同业务数据的预处理方式也不同，一般来讲原始服务器日志数据脏数据的形成原因包括：缩写词不统一，数据输入错误，不同的惯用语，重复记录，丢失值，不同的计量单位，过时的编码等。相应的，数据预处理内容包括数据清理、数据集成、数据变换、数据归约、数据离散化。

  1）数据清理包括格式标准化、异常数据清除、错误纠正、重复数据的清除。对于手机主题用户数据来讲，引起空缺值的原因主要是用户设备异常造成的，有些时候是因为与其他已有数据不一致而被删除或数据的改变没有进行日志记载。根据数据空缺情况的不同有不同的处理方式：
  \begin{itemize}
  \item 忽略元组。当一个记录中有多个属性值空缺、特别是关键信息丢失时,已不能反映真实情况,它的效果非常差。
  \item 去掉属性。缺失严重时,已无挖掘意义。
  \item 人工填写空缺值。但是工作量大且可行性低。
  \item 默认值。比如使用unknown或-∞。
  \item 使用属性的平均值填充空缺值。
  \item 预测最可能的值填充空缺值。使用贝叶斯公式或判定树这样的基于推断的方法。
  \end{itemize}

  2）数据集成就是将多个数据源中的数据整合到一个一致的存储中，需要注意以下几个情况：
  \begin{itemize}
  \item 模式集成。整合不同数据源中的元数据时的实体识别问题，比如匹配俩个表中的用户ID，A.custId=B.customerNo。
  \item 检测/解决数值冲突。对现实世界中的同一实体,来自不同数据源的属性值可能有所不同，如同表示停留时长，A表单位是秒，B表单位为毫秒。
  \item 多表之间的数据冗余。同一属性在不同的数据库中会有不同的字段名，有些时候冗余可以被相关分析检测出来，计算公式如所示，其中$\overline{A}$和$\overline{B}$表示为字段A和B的平均值，$\sigma_A和\sigma_B$表示其的标准差。仔细将多个数据源中的数据集成起来,能够减少或避免结果数据中的冗余与不一致性,从而可以提高挖掘的速度和质量。
  \begin{equation}
    r_{A,B} = \frac{\sum (A-\overline{A})(B-\overline{B})}{(n-1)\sigma_A\sigma_B}
    \label{F-Measure}
  \end{equation}
  \end{itemize}

  3）数据变换包括数据的平滑变换、数据聚集和数据规范化。所谓规范化是指将数据按比例缩放,使之落入一个小的特定区间，有如下几种方式：
  \begin{itemize}
  \item 最小-最大规范化。如\autoref{equ:minMax}所示，原始数值范围为[min,max]，通过公式映射到新区间[newMin,newMax]，$v'$表示属性v的公式映射。
  \begin{equation}
    v' = \frac{v-min}{max-min}(newMax-newMin)+newMin
    \label{equ:minMax}
  \end{equation}
  \item z-score规范化。Z-score表示原始数据偏离均值的距离长短，而该距离度量的标准是标准方差，如果统计数据量足够多，Z-score数据分布可以满足，68\%的数据分布在“-1”与“1”之间，95\%的数据分布在“-2”与“2”之间，99\%的数据分布在“-3”与“3之间”。如\autoref{equ:zscore}所示，其中v是原始数据，v'为v的映射，mean是全部数据的均值，$\sigma$为标准方差。
  \begin{equation}
    v' = \frac{v-mean}{\sigma}
    \label{equ:zscore}
  \end{equation}
  \item 小数定标规范化，小数定标规范化通过移动数据A的小数点位置进行规范化，小数点的移动位置依赖数据A的最大值。如\autoref{equ:small}所示，其中j是使$Max(| v'|)<1$的最小整数。
  \begin{equation}
    v' = \frac{v}{10^j}
    \label{equ:small}
  \end{equation}
  \end{itemize} 

  4）数据归约是数据字段从源数据集中得到数据集的归约表示。数据仓库中往往存有海量数据,在其上进行复杂的数据分析与挖掘需要很长的时间，通过数据归约使得数据小得多,且可以产生相同的分析结果，需要注意的是用于数据归约的时间不应当超过或“抵消”在归约后的数据上挖掘节省的时间。数据归约策略包括：
  \begin{itemize}
  \item 数据立方体聚集。最底层的方体对应于基本方体，基本方体对应于感兴趣的实体。在数据立方体中存在着不同级别的汇总，每次较高层次的抽象将进一步减少结果数据。数据立方体提供了对预计算的汇总数据的快速访问，所有尽可能对于汇总数据的查询使用数据立方体。
  \item 维归约，通过删除不相干的属性或维减少数据量，维归约又属性子集选择和启发式俩种实现方式。属性子集选择是指找出最小属性集,使得数据类的概率分布尽可能的接近使用所有属性的原分布，同时减少出现在发现模式上的属性的数目,使得模式更易于理解。启发式的方法有：逐步向前选择；逐步向后删除；向前选择和向后删除相结合；判定归纳树；基于统计分析的归约如主成分分析、回归分析等。
  \end{itemize}

  6)数据离散化,即连续属性的范围划分为区间，减少给定连续属性值的个数，区间的标号可以代替实际的数据值。
  \begin{itemize}
  \item 概念分层。通过使用高层的概念替代底层的属性值，如用青年、中年、 老年代替年龄数据值。
  \item 分箱（binning）。分箱技术递归的用于结果划分,可以产生概念分层。
  \item 直方图分析（histogram）。直方图分析方法递归的应用于每一部分,可以 自动产生多级概念分层。
  \item 聚类分析。将数据划分成簇,每个簇形成同一个概念层上的一个节点,每个簇可再分成多个子簇,形成子节点。
  \item 基于熵的离散化。
  \item 自然划分。将数值区域划分为相对一致的、易于阅读的、看上去更直观或自然的区间，划分步骤：如果一个区间最高有效位上包含3,6,7或9个不同的值,就将该区间划分为3个等宽子区间；如果一个区间最高有效位上包含2,4,或8个不 同的值,就将该区间划分为4个等宽子区间；如果一个区间最高有效位上包含1,5,或10个 不同的值,就将该区间划分为5个等宽子区间；将该规则递归的应用于每个子区间,产生给定数值属性的概念分层；对于数据集中出现的最大值和最小值的极端分布,为了避免上述方法出现的结果扭曲,可以在顶层分段时,选用一个大部分的概率空间，如5\%-95\%。
  \end{itemize}

\section{用户兴趣探索的算法模型}
用户兴趣探索就是不断学习用户所感兴趣的内容反馈给个性化推荐模型去加强推送相关内容，本节首先介绍用户兴趣模型的基本概念，然后介绍算法模型的组成结构：用户异常兴趣探测，用户小众兴趣标签的挖掘和用户满意度量化，用户兴趣衰减算法。

  \subsection{基本概念概述}
  实体域。当我们想基于用户行为分析来建立用户兴趣模型时，我们必须把用户行为和兴趣主题限定在一个实体域上。个性化推荐落实在具体的推荐中都是在某个实体域的推荐。对于手机主题应用市场来说，实体域包括所有的主题，背景图片，铃声，闹铃等。

  用户行为。浏览，点击，下载，试用，购买，评论等都可是用户行为。本文所指的用户行为都是指用户在某实体域上的行为。比如用户在手机铃声产生的行为。
  用户兴趣。用户的兴趣维度，同样是限定在某实体域的兴趣，通常以标签+权重的形式来表示。比如，对于手机主题，用户兴趣向量可以是「动漫，0.6」，「体育，0.1」，「情感，0.7」等分类标签。值得一提的是，用户兴趣只是从用户行为中抽象出来的兴趣维度，并无统一标准。而兴趣维度的粒度也不固定，如「体育」，「电影」等一级分类，而体育下有「篮球」，「足球」等二级分类，篮球下有「NBA」，「CBA」，「火箭队」等三级分类。我们选取什么粒度的兴趣空间取决于具体业务模型。

  兴趣空间。在同一层次上兴趣维度的集合，比如手机主题中，可以用「热门」，「游戏」，「限时特价」，「科技」来构成一个程序员兴趣标签空间，也可以用「二次元」，「萝莉」，「魔幻」，「纯真」，「召唤兽」·····「法术」等构成一个动漫兴趣标签空间。


  \subsection{用户异常兴趣探测算法}
  统计学中的数据异常值是一个测量变量中的随机错误或偏差，信息安全学中的数据异常是指引起不正确属性值的原因包括恶意hack行为、数据输入等。传统的的异常兴趣检测是基于统计。首先根据现有用户画像建立数据统计模型，异常是那些模型不能完美拟合或是相对远离预测值的对象，对于常用的回归模型，如\autoref{pic:hl_regression}所示。但缺点是用户兴趣概率分布模型计算比较耗费计算资源。
  \begin{figure}
  \centering
    \framebox{\includegraphics[scale=0.5]{figures/hl_regression}}
    \figcaption{回归异常值检测}
    \label{pic:hl_regression}
  \end{figure}

  本文中涉及到的异常是指用户兴趣行为的差异化趋势，比如，用户小磊每次都会浏览动漫、美少女主题，但是有一天却购买了一款汽车手机主题，那么程序可以检测到这个异常情况，然后将汽车标签更新到用户画像中，并作为个性化推荐的依据。事实上用户兴趣迭代过程可以在很短的时间内完成，基于 hive + MapReduce 平台的时长维度为天，而基于 kafka + spark 平台可以将时长维度降到小时级别。用户异常兴趣检测算法要从用户的行为和偏好中发现新的兴趣标签，并基于此给予推荐，工作内容包括收集用户的最新的行为数据是并分析得出异常标签，算法如\autoref{algo:newTagsExpore}所示
  \begin{algorithm}
  %% \SetLine
  \KwIn{用户画像数据 userProfile ,用户显示、隐式行为数据 logUsers}
  \KwOut{用户异常兴趣标签 newUsersTags}
  init newUsersTags;\\
  \For{$(user_i in logUsers)$}{
    \For{$(tag_j in user_i)$}{
      \If{$(tag_j.weight==0)$}{
        //若标签权重已经为 0,该用户兴趣标签将被删除\\
        remove $tag_j$;
      }
      \Else {
        //成功探测到新用户兴趣标签\\
        temp.get($user_i$).set($tag_j$);
      }
    } 
  }
  \Return temp;
  \caption{用户异常兴趣探测}
  \label{algo:newTagsExpore}
  \end{algorithm}

  \subsection{长尾标签抽取算法}
  标签集中度(tagFocus)是指，如果某个标签在一类主题中出现的频率高，其他主题类型很少出现，则认为此兴趣标签具有很好的类别区分能力。这是因为包含兴趣标签t的主题越少，也就是n越小，则说明标签t具有很好的兴趣区分，则其探索权重越大。如果某一类主题包C中包含兴趣标签t的个数为tagInThemeNum，而其它类包含t的总数为tagInOtherNum，则所有包含t的主题数n=tagInThemeNum+tagInOtherNum，当m大的时候，n也大，标签权重值会小，就说明该标签t类别区分能力不强。实际上，如果一个标签在一个类的主题中频繁出现，则说明该标签能够很好代表这类主题的特征，这样的标签应该给它们赋予较高的权重，并选来作为该类主题的特征向量以区别于其它类主题。热度(tagPopular)指的是某一个给定标签在用户画像中出现的频率。例如在300万用户总数中，十分之一的用户标签中有"火影"标签，那么其热度为0.1，除此之外有些标签如"精品"，"气质"等标签占了总词频的80\%以上，而它对区分主题类型几乎没有用。我们称这种词叫“应删标签”。即应删除词的权重应该是零，也就是说在度量相关性是不应考虑它们的频率。标签集中度公式如\autoref{equ:focus}所示，我们很容易发现，如果一个标签只在很少的主题包中出现，我们通过它就容易锁定搜索目标，它的权重也就应该大。反之如果一个词在大量主题包中出现，我们看到它仍然不很清楚要找什么内容，因此它应该小。热度公式如\autoref{equ:hot}所示。长尾标签抽取算法如\autoref{algo:longTailTags}所示。
    \begin{equation}
      tagFocus=log\frac{|tagInThemeNum|}{|tagInThemeNum+tagInOtherNum|}
      \label{equ:focus}
    \end{equation}

    \begin{equation}
      tagPopular=log\frac{|peopleLikeTagNum|}{|allPeople|}
      \label{equ:hot}
    \end{equation}

  \begin{algorithm}
  %% \SetLine
  \KwIn{用户画像数据 userProfile ,用户显示、隐式行为数据 logUsers}
  \KwOut{长尾兴趣标签 longTailTags}
  init longTailTags;\\
  \For{$(user_i in logUsers)$}{
    \For{$(tag_j in user_i)$}{
      $weight_{ij}$=$tag_j$.tagFocus/$tag_j$.tagPopular;\\
      \If{$(weight_{ij}<=threshold)$}{
        //若标签权重小于阈值,该用户兴趣标签将被删除\\
        remove $tag_j$;
      }
      \Else {
        //成功探测到新用户兴趣标签\\
        longTailTags.get($user_i$).set($tag_j$);
      }
    } 
  }
  \Return longTailTags;
  \caption{长尾兴趣探测}
  \label{algo:longTailTags}
  \end{algorithm}

  \subsection{用户满意度量化算法}
  要从用户的行为和偏好中量化用户满意度，并基于此实现兴趣标签探索，如何收集用户的偏好行为成为用户兴趣探索效果最基础的决定因素。用户有很多方式向系统提供自己的偏好信息，而且不同的应用也可能大不相同。
    \begin{table}[htp]
    \centering
    \tabcaption{用户行为和其权重}
    \label{tab:userAction}
    \begin{tabular}{ |c|c|p{4cm}|p{5cm}|c|} \hline
     用户行为 & 类型 & 特征 & 作用 & 权重\\ \hline
     评分 & 显式 & 整数量化的偏好，可能的取值是 [0, 5] & 通过用户对物品的评分，可以精确的得到用户的满意度，但是噪声比较大，比如遇到好评返现活动 & 1\\ \hline
     分享 & 显式 & 布尔量化的偏好，取值是 0 或 1 & 通过用户对物品的投票，可以精确的得到用户的喜好度，同时可以推理得到被转发人的兴趣取向（不太精确）& 2\\ \hline
     评论 & 显式 & 一段文字，需要进行文本分析，得到偏好 & 通过分析用户的评论，可以得到用户的情感：喜欢还是讨厌 & 1\\ \hline
     赞/踩 & 显示 & 布尔量化的偏好，取值是 0 或 1 & 带有很强的个人喜好度 & 3 \\ \hline
     购买、试用 & 显式 & 布尔量化的偏好，取值是 0 或 1 & 用户的购买是很明确的说明这个项目它感兴趣。& 3 \\ \hline
     点击流 & 隐式 & 包括滑屏频率，滑屏次数，屏停留时长，用户对物品感兴趣，需要进行分析，得到偏好 & 用户的点击一定程度上反映了用户的注意力，所以它也可以从一定程度上反映用户的喜好。& 1 \\ \hline
     停留时长 & 隐式 & 一组时间信息,噪音大,需 要进行去噪,分析,得到偏 好 & 用户的页面停留时间一定程度上反映了用户的注意力和喜好，但噪音偏大，不好利用。比如说用户在浏览一个主题的时候，丢下手机和同学出去踢球去了，页面提留时长可能会很长 & 1 \\ \hline
    \end{tabular}
    \end{table}
  \autoref{tab:userAction}列举的用户行为都是比较通用的，设计人员也可以根据实际情况添加特殊的用户行为，并用他们表示用户对物品的喜好。一般来讲我们提取的用户行为一般都多于一种，根据不同行为反映用户喜好的程度将它们进行加权，得到用户对于物品的总体喜好。显式的用户反馈比隐式的权值大，但比较稀疏，毕竟进行显示反馈的用户是少数；而隐式用户行为数据是用户在使用应用过程中产生的，它可能存在大量的噪音和用户的误操作，我们可以通过经典的数据挖掘算法过滤掉行为数据中的噪音，这样可以是我们的分析更加精确。然后是归一化操作，因为不同行为的数据取值可能相差很大，比如，用户的浏览数据必然比购买数据大的多，如何将各个行为的数据统一在一个相同的取值范围中，从而使得加权求和得到的总体喜好更加精确，就需要我们进行归一化处理使得数据取值在 [0,1] 范围中。算法如\autoref{algo:longTailTags}所示。

  \begin{algorithm}
  %% \SetLine
  \KwIn{用户显示、隐式行为数据 logUsers}
  \KwOut{用户行为权重 userActionWeight}
  init userActionWeight;\\
  \For{$(user_i in logUsers)$}{
    \For{$(action_j in user_i)$}{
      //获取用户此次行为的偏好权重并做归一化\\
      $weight_{ij}$=getWeigth($action_j$);
      \If{$(user_i exsit in userActionWeight)$}{
        //对用户行为做加权处理。\\
        double remaind=userActionWeight.get($user_i$);
        userActionWeight.get($user_i$).set(remaind+$action_j*weight_j$);
      }\Else{
        userActionWeight.get($user_i$).set($action_j*weight_j$);
      }
    } 
  }
  \Return userActionWeight;
  \caption{用户满意度量化算法}
  \label{algo:userActionWeight}
  \end{algorithm}

  \subsection{标签权重的线性衰减}
  实际中使用的是基于时间衰减的用户兴趣检测模型。该算法的特点是基于向量空间模型的用户画像建模，结合手机主题用户兴趣偏好变化频繁的特点，根据时间因素权重自动进行衰减，以此反映出用户兴趣的变化。该模型是指用户对资源项目的评分仅代表评价当时的兴趣度，随着时间的推移，用户对该资源项目的评分将规律性地自动衰减，当项目评分衰减到 0 时，该资源项目将被兴趣模型所淘汰。评分衰减可以按照线性规律进行，如\autoref{pic:hl_lineReg}所示。算法描述如\autoref{algo:init_userProfile}所示。
  \begin{algorithm}
  %% \SetLine
  \KwIn{用户画像模型中所有用户兴趣哈希表 users{}}
  \KwOut{更新后的所有用户兴趣哈希表 users{}}
  \For{$(user_i in users)$}
  {
    //考虑到断电或意外关机等原因导致系统中断运行的特殊情况，算法加入了临时变量temp\\
    temp.add($user_i$.profile{});
  }
  \For{$(user_i in logUsers)$}
  {
    \For{$(tag_j in user_i)$}{
      \If{$(tag_j==0)$}{
        //若标签权重已经为 0,该用户兴趣标签将被删除\\
        remove $tag_j$;
      }\ElseIf {$(tag_j$ exsit in temp$(user_i)$}{
        //若存在新的评分值,则更新为新标签权重
        temp.get($user_i$).set($tag_j$);
      }\Else{
        //否则的话，将偏好值减少 0.5，进行衰减\\
        temp.get($user_i$).set($tag_j$-0.5);
      }
    }
  }
  \Return temp;
  \caption{用户画像线性衰减}
  \label{algo:init_userProfile}
  \end{algorithm}

  \begin{figure}
  \centering
    \framebox{\includegraphics[scale=0.5]{figures/hl_lineReg}}
    \figcaption{线性衰减模型}
    \label{pic:hl_lineReg}
  \end{figure}

\section{用户兴趣探索评估方法}
评价方法分为以下俩种：线下测试和线上测试。首先介绍线下测试基本概念，然后具体介绍工业界常用的线上A/B测试。
  \subsection{线下测试}
  笔者曾参加过2014年阿里举办的大数据竞赛，当时主要用线下测试评估算法模型优劣，总结出的基本准则是：不要过早优化模型调参和模型融合，这两部分应当留到中后期来做；不要一次性添加大量特征，最好一部分一部分添加，这样会对添加的特征效果有个大体的认识。线下测试具体步骤如下：
  \begin{itemize}
  \item 选定数据集选择和应用相关的数据集。数据需要是无偏的（unbiased），通过随机抽样能满足要求。将现有数据集分成训练集(train set) 验证集(validation set) 测试集(test set)。其中训练集用来估计模型，验证集用来确定网络结构或者控制模型复杂程度的参数，而测试集则检验最终选择最优的模型的性能如何。一个典型的划分是训练集占总样本的50％，而其它各占25％。样本少的时候可以留少部分做测试集。然后对其余N个样本采用K折交叉验证法。就是将样本打乱，然后均匀分成K份，轮流选择其中K－1份训练，剩余的一份做验证，计算预测误差平方和，最后把K次的预测误差平方和再做平均作为选择最优模型结构的依据。
  \item 建立算法模型.
  \item 准确度的评估、反馈。准确度的评估方法有Mean Absolute Error和Root Mean Squared Error，对于一个元素是 user-item 对(u， i)的集合 T，实际评分为 $r_{ui}$，预测评分为 $\hat{r}_{ui}$，无论是通过 MAE 还是 RMSE 计算，最终的结果值越小证明结果越准确。但从公式可以看出，RMSE 通过平方扩大了偏离量，同样的两组结果用RMSE得出的差异值将比MAE更大。对应公式如下：
  \begin{equation}
    MAE = \frac{1}{|T |} \sum_{(u，i)\in T}|\hat{r}_{ui}-r_{ui}|
    \label{cosine-similiarity}
  \end{equation}
  \begin{equation}
    RMSE = \sqrt{\frac{1}{|T |} \sum_{(u，i)\in T}(\hat{r}_{ui}-r_{ui})^2}
    \label{cosine-similiarity}
  \end{equation}
  \end{itemize}

  \subsection{线上A/B测试}
  在太平洋东部加拉帕戈斯（Galapagos）的一个小岛上有一种名叫达尔文雀的鸟，一部分生活在岛的西部，另一部分生活在岛的东部，由于生活环境的细微不同它们进化出了不同的喙，如\autoref{pic:hl_abbird}所示，这被认为是自然选择学说上的一个重要例证。同样一种鸟，究竟哪一种喙更适合生存呢？自然界给出了她的解决方案，让鸟儿自己变异（设计多个方案），然后优胜劣汰。具体到达尔文雀这个例子上，不同的环境中喙也有不同的解决方案。
  \begin{figure}
  \centering
    \framebox{\includegraphics[scale=0.45]{figures/hl_abbird}}
    \figcaption{达尔文雀}
    \label{pic:hl_abbird}
  \end{figure}
  上面的例子包含了A/B测试最核心的思想：多个方案并行测试；每个方案只有一个变量（比如鸟喙）不同；以某种规则优胜劣汰。评判用户画像模型的效率高低，主要是看该模型带来的点击率、转换率等指标数据，其他统计量见\autoref{tab:abtest}所示。理论上评测推荐系统的指标有用户满意度、预测准确度、覆盖率、多样性、新颖度、惊喜度、信任度、实时性、健壮性等。然而商业开发中，评测推荐结果只看重一个指标：点击转化率。能够提升商业价值，给业务带来更多利益的推荐系统，就是好的推荐系统。
  \begin{table}[htp]
  \centering
  \tabcaption{A/B测试主要评估指标}
  \label{tab:abtest}
  \begin{tabular}{ |c|p{10cm}| } \hline
   指标 & 描述 \\ \hline
   访客数 & 访客数就是指一天之内到底有多少不同的用户访问了你的网站。访客数要比IP数更能真实准确地反映用户数量。\\ \hline
   浏览量 & 即Page View，浏览量和访问次数是呼应的。用户访问网站时每打开一个页面，就记为1个PV。同一个页面被访问多次，浏览量也会累积。 \\ \hline
   点击转化率 & 点击转化率计算公式:点击转化率 = 成交笔数/浏览量 *100\%，成交笔数影响着成交金额，所以点击转化率成为了衡量推荐系统效果的重要数据之一。\\ \hline
   停留时长 & 停留时长是用户访问网站的平均停留时间，是衡量网站用户体验的一个重要指标。如果用户不喜欢主题包的内容，可能稍微看一眼就关闭页面了，那么停留时长就很短;如果用户对页面的内容很感兴趣，停留时长就很长。\\ \hline
   跳出率 & 跳出率是指访客来到网站后，只访问了一个页面就离开网站的访问次数占总访问次数的百分比，跳出率越低说明流量质量越好，用户对网站的内容越感兴趣。 \\ \hline
   其他指标 & 各种辅助性指标如点击量/用户，购买量/用户，下载量/用户等。\\ \hline
  \end{tabular}
  \end{table}

  A/B测试对用户画像建模的作用有三个：特征提取，一些标签对用户的兴趣有强相关作用，如性别标签，有些标签是弱相关作用，如用户职业标签，A/B测试需要筛选出强相关标签，过滤掉弱相关标签；权重量化，根据A/B测试实验显示，发现用户画像中的最近点击标签、最近关注标签所占权重比想象中的要大；标签组合，有些标签是冗余的，只需从中选一即可。A/B测试具体实现步骤如下：

  \begin{itemize}
  \item 方案设计。实验之前需得到一个基准版本，然后把又争议的标签按照优先度列举出来决定是否实验。真正的A/B测试只应一次改动一个地方，这意味着标签选择、权重量化、标签组合要分开来测试。
  \item 确定数据评估方案。根据实验内容不同评估它们好坏的标准也不同，如果是标签选择那么衡量的主要指标是点击量，如果是权重量化那么衡量的主要指标是点击转换率。
  \item 流量分配。为了试实验所得数据具备统计意义，能准确反映用户的真实行为，需要对流量设置一个下限。除此之外，为了使各个方案具有可比性， A、B俩个方案的流量必须是相等的。
  \item 测试周期。根据所需测试的项目的不同测试周期也有所不同，如添加一个地理标签需要的测试周期以天为单位，如果涉及到多个标签的权重变动则需要测试周期以周为单位。
  \item 评估结果。适者胜出，其代表的数据作为下一轮回A/B测试的基准版本。
  \item 建立通用的数据评估题型。在经过各种类型A/B测试实验后，已经积累很多的评估指标，有必要把这些指标抽象出来形成一个通用的数据评估模型，减少以后实验的重复设计评估指标的时间。
  \end{itemize}

\section{总结}
这一章主要研究了标签动态变化的对推荐系统的影响，实际中用户同时会受到社会因素和个人因素的影响,但这两种因素在会产生不同强度的影响。在快速变化的系统中,用户行为更加会受到社会因素 的影响,而在变化相对较慢的系统中,用户行为则更加受到个人因素的影响。本章首先介绍了用户行为数据的存储方式以及基于此的用户行为数据的的预处理。然后介绍了用户兴趣探索的组成内容，包括用户异常兴趣探测、长尾标签抽取、用户满意度量化、标签权重的线性衰减。最后给出了用户兴趣探索评估方法，包括离线和在线俩种。下一章节主要介绍如何把用户画像和兴趣探索融入到推荐系统中，从而搭建出一个具有长尾性、实时性的推荐系统。